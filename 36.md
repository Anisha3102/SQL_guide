# What is denormalization? When is it used?

- Denormalization is the process of intentionally introducing redundancy into a normalized database design by combining tables or adding duplicate data.

- In normalization → data is split into multiple tables to reduce redundancy and ensure consistency.

- In denormalization → some of this separation is relaxed to improve query performance (fewer joins).

##### In short:

- Normalization = minimize redundancy (optimize for data integrity).

- Denormalization = reintroduce redundancy (optimize for performance).

## When is Denormalization Used?

- Denormalization is used when performance is more important than strict normalization. Common scenarios:

- Improve Query Speed

- When queries require too many joins (slowing down performance).

> Example: In a reporting system, instead of joining Orders and Customers every time, store customer_name directly in the Orders table.

- Read-Heavy Workloads

- In analytics / data warehouses where reads >> writes.

> Example: Star schema in OLAP databases.

- Pre-computed / Aggregated Data

- Storing total sales, counts, or averages in a summary table.

- Avoids recalculating expensive aggregations repeatedly.

- Caching Frequent Data

- Adding frequently accessed values (like product_price) into the OrderDetails table to avoid extra joins.

- Distributed Databases / NoSQL

- In systems like MongoDB or Cassandra, denormalization is common since joins are costly or not supported.

## Example
### Normalized (3NF)

### Orders

| order_id | customer_id	  | product_id |

Customers
| customer_id | customer_name |

Products
| product_id | product_name | price |

- To fetch order details → needs joins across 3 tables.

### Denormalized

### Orders
| order_id | customer_id | customer_name | product_id | product_name | price |

- Customer and product details stored directly → fewer joins → faster queries, but redundant data.

## Pros & Cons

### Advantages

- Faster reads (fewer joins).

- Simplifies complex queries.

- Useful in reporting, OLAP, and data warehouses.

### Disadvantages

- Data redundancy → storage overhead.

- Higher risk of inconsistency (must update in multiple places).

- More complex write operations.

## In short:
- Denormalization is used to speed up queries in read-heavy systems (like reporting, analytics, data warehouses) by sacrificing storage efficiency and strict consistency.- 